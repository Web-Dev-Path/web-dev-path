// sample data till incorporating dev.to API
// response on https://dev.to/api/articles/1787452
export const post = {
  type_of: 'article',
  id: 1787452,
  title: 'My Experience with Apache Airflow',
  description:
    '1. Get Accepted for the MLH Fellowship Program   I got accepted for the MLH Fellowship...',
  readable_publish_date: 'Mar 12',
  slug: 'my-experience-with-apache-airflow-1dpl',
  path: '/satoshi-sh/my-experience-with-apache-airflow-1dpl',
  url: 'https://dev.to/satoshi-sh/my-experience-with-apache-airflow-1dpl',
  comments_count: 0,
  public_reactions_count: 6,
  collection_id: null,
  published_timestamp: '2024-03-12T01:02:43Z',
  positive_reactions_count: 6,
  cover_image:
    'https://media.dev.to/cdn-cgi/image/width=1000,height=420,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fgdmwm1kg8v5mosqz297l.jpg',
  social_image:
    'https://media.dev.to/cdn-cgi/image/width=1000,height=500,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fgdmwm1kg8v5mosqz297l.jpg',
  canonical_url:
    'https://dev.to/satoshi-sh/my-experience-with-apache-airflow-1dpl',
  created_at: '2024-03-12T01:02:45Z',
  edited_at: '2024-06-01T17:38:39Z',
  crossposted_at: null,
  published_at: '2024-03-12T01:02:43Z',
  last_comment_at: '2024-03-12T01:02:43Z',
  reading_time_minutes: 3,
  tag_list: 'intern, airflow, python, dataengineering',
  tags: ['intern', 'airflow', 'python', 'dataengineering'],
  body_html:
    '\u003cp\u003e\u003ca href="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F3zxkiuopj3h4c6ogul0n.png" class="article-body-image-wrapper"\u003e\u003cimg src="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F3zxkiuopj3h4c6ogul0n.png" alt="Apache Logo" loading="lazy" width="800" height="309"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003ch3\u003e\n  \u003ca name="1-get-accepted-for-the-mlh-fellowship-program" href="#1-get-accepted-for-the-mlh-fellowship-program"\u003e\n  \u003c/a\u003e\n  1. Get Accepted for the MLH Fellowship Program\n\u003c/h3\u003e\n\n\u003cp\u003eI got accepted for the MLH Fellowship Program 2024 Spring and had an opportunity to work for Apache Airflow. Apache Airflow is an open-source workflow management platform for data engineering pipelines, which is an established and widely used project in the data engineering community.\u003c/p\u003e\n\n\u003cp\u003eIf you are interested in the program, I also wrote about how I prepared my application \u003ca href="https://dev.to/satoshi-sh/how-i-prepared-mlh-fellowship-application-as-a-career-switcher-1co9"\u003ehere\u003c/a\u003e    \u003c/p\u003e\n\n\u003cp\u003eAs I passed the mid-term of the MLH Fellow Program, I would like to share what I have done so far for the project. \u003c/p\u003e\n\n\u003ch3\u003e\n  \u003ca name="2-my-contributions" href="#2-my-contributions"\u003e\n  \u003c/a\u003e\n  2. My Contributions\n\u003c/h3\u003e\n\n\u003cp\u003eApache Airflow is a large repository. I contributed to the project from various fields.\u003cbr\u003e\nI can categorize my contributions into 5 fields \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eDocumentation\u003c/li\u003e\n\u003cli\u003eFrontEnd\u003c/li\u003e\n\u003cli\u003eCode Formatting\u003c/li\u003e\n\u003cli\u003eBackEnd API\u003c/li\u003e\n\u003cli\u003eUpgrading Dependency (Connexion V3)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch4\u003e\n  \u003ca name="21-documentation" href="#21-documentation"\u003e\n  \u003c/a\u003e\n  2.1 Documentation\n\u003c/h4\u003e\n\n\u003cul\u003e\n\u003cli\u003eTypo in the URL \u003ca href="https://github.com/apache/airflow/pull/37294"\u003e#37294\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eFix broken hyperlink \u003ca href="https://github.com/apache/airflow/pull/37526"\u003e#37526\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eFirst, I needed to set up a developer environment to start contributing. Fortunately, Apache Airflow makes the process easier with Breeze. I just needed to follow the documentation to set up Breeze. While reading the documentation, I found some hyperlinks are broken. Fixing the broken link was my first contribution to the project. \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eAdded Supported Database Types \u003ca href="https://github.com/apache/airflow/pull/37376"\u003e#37376\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eOn the Airflow Slack, a user requested an available SQL list. I added the list document using Sphinx.\u003c/p\u003e\n\n\u003cp\u003e\u003ca href="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fkjrhy4b0y0l0432at7nc.png" class="article-body-image-wrapper"\u003e\u003cimg src="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fkjrhy4b0y0l0432at7nc.png" alt="Slack Request" loading="lazy" width="800" height="138"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003ca href="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F264ndpkkg4i0mwz2k22e.png" class="article-body-image-wrapper"\u003e\u003cimg src="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F264ndpkkg4i0mwz2k22e.png" alt="Supported Database Types" loading="lazy" width="800" height="458"\u003e\u003c/a\u003e \u003c/p\u003e\n\n\u003ch4\u003e\n  \u003ca name="22-frontend" href="#22-frontend"\u003e\n  \u003c/a\u003e\n  2.2 FrontEnd\n\u003c/h4\u003e\n\n\u003cul\u003e\n\u003cli\u003eMomento Warning \u003ca href="https://github.com/apache/airflow/issues/37281"\u003e#37281\u003c/a\u003e (Create an issue)\u003c/li\u003e\n\u003cli\u003eAdded shutdown color to the STATE_COLORS \u003ca href="https://github.com/apache/airflow/pull/37295"\u003e#37295\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eUpdate searchBlogsPosts.js to avoid errors \u003ca href="https://github.com/apache/airflow-site/pull/956"\u003e#956\u003c/a\u003e (apache/airflow-site)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAs I\'m into web development, I have a habit of keeping the browser terminal open to see any warnings and errors. Once I found them, I fixed them right away. \u003c/p\u003e\n\n\u003cp\u003e\u003ca href="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F3oonjyvmntzfdpzma3bl.png" class="article-body-image-wrapper"\u003e\u003cimg src="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F3oonjyvmntzfdpzma3bl.png" alt="browser-warning" loading="lazy" width="800" height="382"\u003e\u003c/a\u003e \u003c/p\u003e\n\n\u003cp\u003e\u003ca href="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fpgswff6qcwq5ctn8lt5i.png" class="article-body-image-wrapper"\u003e\u003cimg src="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fpgswff6qcwq5ctn8lt5i.png" alt="browser-warning2" loading="lazy" width="800" height="361"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003ch4\u003e\n  \u003ca name="23-code-formatting" href="#23-code-formatting"\u003e\n  \u003c/a\u003e\n  2.3 Code Formatting\n\u003c/h4\u003e\n\n\u003cul\u003e\n\u003cli\u003eApplied D401 to airbyte files. \u003ca href="https://github.com/apache/airflow/pull/37370"\u003e#37370\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eD105 checks - airflow.ti_deps \u003ca href="https://github.com/apache/airflow/pull/37578"\u003e#37578\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003eD105 Check on Amazon \u003ca href="https://github.com/apache/airflow/pull/37764"\u003e#37764\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eAs Apache Airflow has so many contributors(2895 contributors when I\'m writing this post), we need code formatting tests. The maintainers added a new format check named D401 and D105. \u003c/p\u003e\n\n\u003cp\u003eOnce introduce the code formatting test, we need to update lots of files. So they split the work. I took modules to update the code to follow the code format.  \u003c/p\u003e\n\n\u003cp\u003e\u003ca href="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fjkwnrluev37cxghlbtte.png" class="article-body-image-wrapper"\u003e\u003cimg src="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fjkwnrluev37cxghlbtte.png" alt="Updated Codes" loading="lazy" width="800" height="434"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003ch4\u003e\n  \u003ca name="24-backend-api" href="#24-backend-api"\u003e\n  \u003c/a\u003e\n  2.4 Backend API\n\u003c/h4\u003e\n\n\u003cul\u003e\n\u003cli\u003eFilter Datasets by associated dag_ids (GET /datasets) \u003ca href="https://github.com/apache/airflow/pull/37512"\u003e#37512\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003e\u003ca href="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fs2oz9ae9vh5u2ftafhsp.png" class="article-body-image-wrapper"\u003e\u003cimg src="https://media.dev.to/cdn-cgi/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fs2oz9ae9vh5u2ftafhsp.png" alt="Request to add another filter" loading="lazy" width="800" height="153"\u003e\u003c/a\u003e\u003c/p\u003e\n\n\u003cp\u003eBefore this implementation, the endpoint can only filter by the database URL. Now we can filter the datasets by associated dag_ids(task id). This update makes it easy to see what datasets are connected to a dag.\u003c/p\u003e\n\n\u003cp\u003eThrough implementing this feture, I learned many things such as SQLAlchemy, OpenAPI, and the structure of testing units of Airflow.\u003c/p\u003e\n\n\u003ch4\u003e\n  \u003ca name="25-upgrading-dependency-connexion-v3" href="#25-upgrading-dependency-connexion-v3"\u003e\n  \u003c/a\u003e\n  2.5 Upgrading Dependency Connexion V3\n\u003c/h4\u003e\n\n\u003cul\u003e\n\u003cli\u003eMigrate to Connexion v3 \u003ca href="https://github.com/apache/airflow/pull/37638"\u003e#37638\u003c/a\u003e (ongoing)\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eThis is still an ongoing issue. I\'m sure this will be the highlight of my internship. \u003c/p\u003e\n\n\u003cp\u003eApache Airflow is trying to upgrade the connection version from v2 to v3 to enhance security, but there are so many bugs after the upgrade. Me and my teammate Sudipto are in charge of fixing those errors. We created subtasks to fix bugs one by one. \u003c/p\u003e\n\n\u003cp\u003eWhat I have done so far is \u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003eFixed Swagger Configuration \u003c/li\u003e\n\u003cli\u003eFixed Unit tests to create HTTP requests as a user\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003ch3\u003e\n  \u003ca name="3-end-notes" href="#3-end-notes"\u003e\n  \u003c/a\u003e\n  3. End Notes\n\u003c/h3\u003e\n\n\u003cp\u003eThank you for reading this far. Over the past 6 weeks, I\'ve learned a lot, especially through my work on upgrading the dependency, which has helped me grow as a developer. I may write another post when I wrap up this internship.\u003c/p\u003e\n\n\u003cp\u003eI would like to express my gratitude to the MLH Fellowship program for providing me with this valuable learning opportunity, and to RBC (the Royal Bank of Canada) for sponsoring this internship position.\u003c/p\u003e\n\n',
  body_markdown:
    "\n![Apache Logo](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3zxkiuopj3h4c6ogul0n.png)\n### 1. Get Accepted for the MLH Fellowship Program \nI got accepted for the MLH Fellowship Program 2024 Spring and had an opportunity to work for Apache Airflow. Apache Airflow is an open-source workflow management platform for data engineering pipelines, which is an established and widely used project in the data engineering community.\n\nIf you are interested in the program, I also wrote about how I prepared my application [here](https://dev.to/satoshi-sh/how-i-prepared-mlh-fellowship-application-as-a-career-switcher-1co9)    \n\nAs I passed the mid-term of the MLH Fellow Program, I would like to share what I have done so far for the project. \n\n### 2. My Contributions \nApache Airflow is a large repository. I contributed to the project from various fields.\nI can categorize my contributions into 5 fields \n- Documentation\n- FrontEnd\n- Code Formatting\n- BackEnd API\n- Upgrading Dependency (Connexion V3)\n\n#### 2.1 Documentation \n\n- Typo in the URL [#37294](https://github.com/apache/airflow/pull/37294)\n- Fix broken hyperlink [#37526](https://github.com/apache/airflow/pull/37526)\n\nFirst, I needed to set up a developer environment to start contributing. Fortunately, Apache Airflow makes the process easier with Breeze. I just needed to follow the documentation to set up Breeze. While reading the documentation, I found some hyperlinks are broken. Fixing the broken link was my first contribution to the project. \n\n- Added Supported Database Types [#37376](https://github.com/apache/airflow/pull/37376)\n\nOn the Airflow Slack, a user requested an available SQL list. I added the list document using Sphinx.\n\n\n![Slack Request](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/kjrhy4b0y0l0432at7nc.png)\n\n\n![Supported Database Types](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/264ndpkkg4i0mwz2k22e.png) \n\n####2.2 FrontEnd \n- Momento Warning [#37281](https://github.com/apache/airflow/issues/37281) (Create an issue)\n- Added shutdown color to the STATE_COLORS [#37295](https://github.com/apache/airflow/pull/37295)\n- Update searchBlogsPosts.js to avoid errors [#956](https://github.com/apache/airflow-site/pull/956) (apache/airflow-site)\n\nAs I'm into web development, I have a habit of keeping the browser terminal open to see any warnings and errors. Once I found them, I fixed them right away. \n\n\n![browser-warning](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3oonjyvmntzfdpzma3bl.png) \n\n![browser-warning2](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/pgswff6qcwq5ctn8lt5i.png)\n#### 2.3 Code Formatting \n- Applied D401 to airbyte files. [#37370](https://github.com/apache/airflow/pull/37370)\n- D105 checks - airflow.ti_deps [#37578](https://github.com/apache/airflow/pull/37578)\n- D105 Check on Amazon [#37764](https://github.com/apache/airflow/pull/37764)\n\nAs Apache Airflow has so many contributors(2895 contributors when I'm writing this post), we need code formatting tests. The maintainers added a new format check named D401 and D105. \n\nOnce introduce the code formatting test, we need to update lots of files. So they split the work. I took modules to update the code to follow the code format.  \n\n\n![Updated Codes](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/jkwnrluev37cxghlbtte.png)\n\n#### 2.4 Backend API \n- Filter Datasets by associated dag_ids (GET /datasets) [#37512](https://github.com/apache/airflow/pull/37512)\n\n\n![Request to add another filter](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/s2oz9ae9vh5u2ftafhsp.png)\n\nBefore this implementation, the endpoint can only filter by the database URL. Now we can filter the datasets by associated dag_ids(task id). This update makes it easy to see what datasets are connected to a dag.\n\nThrough implementing this feture, I learned many things such as SQLAlchemy, OpenAPI, and the structure of testing units of Airflow.\n\n#### 2.5 Upgrading Dependency Connexion V3\n- Migrate to Connexion v3 [#37638](https://github.com/apache/airflow/pull/37638) (ongoing)\n\nThis is still an ongoing issue. I'm sure this will be the highlight of my internship. \n\nApache Airflow is trying to upgrade the connection version from v2 to v3 to enhance security, but there are so many bugs after the upgrade. Me and my teammate Sudipto are in charge of fixing those errors. We created subtasks to fix bugs one by one. \n\nWhat I have done so far is \n- Fixed Swagger Configuration \n- Fixed Unit tests to create HTTP requests as a user\n\n### 3. End Notes\nThank you for reading this far. Over the past 6 weeks, I've learned a lot, especially through my work on upgrading the dependency, which has helped me grow as a developer. I may write another post when I wrap up this internship.\n\nI would like to express my gratitude to the MLH Fellowship program for providing me with this valuable learning opportunity, and to RBC (the Royal Bank of Canada) for sponsoring this internship position.",
  user: {
    name: 'Satoshi S.',
    username: 'satoshi-sh',
    twitter_username: null,
    github_username: 'Satoshi-Sh',
    user_id: 1212360,
    website_url: 'https://satoshis-developer.xyz/portfolio/',
    profile_image:
      'https://media.dev.to/cdn-cgi/image/width=640,height=640,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Fuser%2Fprofile_image%2F1212360%2F53473333-e3e2-4413-b4eb-7060e6ce3d49.jpeg',
    profile_image_90:
      'https://media.dev.to/cdn-cgi/image/width=90,height=90,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Fuser%2Fprofile_image%2F1212360%2F53473333-e3e2-4413-b4eb-7060e6ce3d49.jpeg',
  },
};

// To get user summary
// Response on https://dev.to/api/users/1212360

export const user = {
  type_of: 'user',
  id: 1212360,
  username: 'satoshi-sh',
  name: 'Satoshi S.',
  twitter_username: 'sato1108ss',
  github_username: 'Satoshi-Sh',
  summary:
    'Satoshi is a full-stack developer, who is looking for opportunities to learn something new. He enjoys collaborating with other developers. Passionate for Open Source projects.',
  location: 'Canada',
  website_url: 'https://satoshis-developer.xyz/portfolio/',
  joined_at: 'Nov 17, 2023',
  profile_image:
    'https://media.dev.to/cdn-cgi/image/width=320,height=320,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Fuser%2Fprofile_image%2F1212360%2F53473333-e3e2-4413-b4eb-7060e6ce3d49.jpeg',
};
